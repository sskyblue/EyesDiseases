{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s4O8k56XdAau"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import  torchvision.transforms as transforms\n",
        "#load pretrained resnet model\n",
        "model = torchvision.models.vgg19(pretrained=False)\n",
        "file_name = \"./checkpoint/LeNet.pt\"\n",
        "checkpoint = torch.load(file_name)\n",
        "model.load_state_dict(checkpoint['net'])\n",
        "print(model)\n",
        "\n",
        "#define transforms to preprocess input image into format expected by model\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                     std=[0.229, 0.224, 0.225])\n",
        "#inverse transform to get normalize image back to original form for visualization\n",
        "inv_normalize = transforms.Normalize(\n",
        "    mean=[-0.485/0.229, -0.456/0.224, -0.406/0.255],\n",
        "    std=[1/0.229, 1/0.224, 1/0.255]\n",
        ")\n",
        "\n",
        "#transforms to resize image to the size expected by pretrained model,\n",
        "#convert PIL image to tensor, and\n",
        "#normalize the image\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    normalize,          \n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def saliency(img, model):\n",
        "    #we don't need gradients w.r.t. weights for a trained model\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "    \n",
        "    #set model in eval mode\n",
        "    model.eval()\n",
        "    #transoform input PIL image to torch.Tensor and normalize\n",
        "    input = transform(img)\n",
        "    input.unsqueeze_(0)\n",
        "\n",
        "    #we want to calculate gradient of higest score w.r.t. input\n",
        "    #so set requires_grad to True for input \n",
        "    input.requires_grad = True\n",
        "    #forward pass to calculate predictions\n",
        "    preds = model(input)\n",
        "    score, indices = torch.max(preds, 1)\n",
        "    #backward pass to get gradients of score predicted class w.r.t. input image\n",
        "    score.backward()\n",
        "    #get max along channel axis\n",
        "    slc, _ = torch.max(torch.abs(input.grad[0]), dim=0)\n",
        "    #normalize to [0..1]\n",
        "    slc = (slc - slc.min())/(slc.max()-slc.min())\n",
        "\n",
        "    #apply inverse transform on image\n",
        "    with torch.no_grad():\n",
        "        input_img = inv_normalize(input[0])\n",
        "    #plot image and its saleincy map\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(np.transpose(input_img.detach().numpy(), (1, 2, 0)))\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(slc.numpy(), cmap=plt.cm.hot)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.show()\n",
        "    "
      ],
      "metadata": {
        "id": "vYpuT7msdE2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image"
      ],
      "metadata": {
        "id": "IUxDgwnBdHCD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = Image.open('images/puppy.jpg').convert('RGB')\n",
        "saliency(img, model)"
      ],
      "metadata": {
        "id": "JGjvFCl3dJD6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
